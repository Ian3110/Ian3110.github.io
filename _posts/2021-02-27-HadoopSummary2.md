---
layout: post
title: "Hadoop 시스템 구성과 아키텍쳐"
categories:
- Hadoop
---

## 서버 구성
---

* 하둡을 구성하는 서버는 클러스터 전체를 관리하는 ‘마스터(Master) 서버군’과 실제로 데이터를 저장하고 처리하는 ‘슬레이브(Slave) 서버군’ 두 종류로 나뉨<br/>
* 이들 서버군이 협력하여 동작함으로써 하나의 하둡 클러스터를 구성함.<br/><br/>

    1) HDFS의 서버<br/>
   -	HDFS의 마스터 서버를 ‘**Name Node**’라고 함. 클러스터 전체에 걸쳐 메타 데이터를 관리함. 
   -	슬레이브 서버를 ‘**Data Node**’라고 부름. 실제 데이터를 읽고 쓰는 역할을 함.<br/><br/>

    2) MapReduce의 서버<br/>
   -	MapReduce의 마스터 서버를 ‘**Job Tracker**’라 부름. 하나의 잡을 태스크라는 복수의 처리로 분할하여 각 슬레이브 서버에 할당함.
   -	슬레이브 서버를 ‘**Task Tracker**’라고 부름. 할당된 태스크를 실행하고 결과를 반환함.<br/><br/>

    3) 마스터 서버인 Name Node, Job Tracker는 각 한 대 씩임. 소규모 하둡 클러스터에서는 Name Node와 Job Tracker가 하나의 장비 내에서 동작하지만, 대규모 클러스터에서는 별도 장비를 사용함.<br/><br/>

    4) 슬레이브 서버는 여러 대로 구성되지만, Data Node와 Job Tracker는 같은 서버에 설치되는 것이 일반적임. 각 Data Node가 읽어 들인 데이터를 같은 서버에 있는 Task Tracker로 처리할 수 있게 하기 위해서. 이들 서버 외에 데이터 삽입이나 잡 실행을 위한 하둡 클라이언트 등도 있음.<br/><br/><br/><br/>

## HDFS (Hadoop Distributed File System)의 기본적인 특징
---
* HDFS는 대용량 파일을 높은 처리량으로 접근할 수 있도록 설계된 분산 파일 시스템.
* 복수의 서버에서 규모가 큰 하나의 파일 시스템을 제공함.
* HDFS상에 배치된 파일은 64MB 단위의 블록으로 분할되어 각 장비에 저장됨.<br/><br/>

###	HDFS의 편리성
-	투과성: 클라이언트 관점에서 파일 시스템 내부에서 복수의 서버가 동작하고 있다는 것을 고려할 필요 없음. 사용자는 파일이 어떻게 블록으로 분할되어 있는지 의식할 필요가 없음.<br/><br/>
-	확장성: Data Node 대수를 늘려 용량과 기본적인 I/O성능(Throughput)을 향상시킬 수 있음.<br/><br/><br/> 

### HDFS의 신뢰성
-	**Replication** 기능: 하나의 파일을 복수의 ‘블록’으로 분할하고, 각각의 블록을 복수의 서버에 다중으로 기록하는 replication 기능 가짐. 기본 설정에서 각 블록이 세 개의 서버로 다중 저장됨. 하나의 서버가 고장 나서 블록에 접근할 수 없게 되더라도 다른 서버에 동일한 블록이 있기에 분산 파일 시스템 전체적으로 데이터 소실 위험이 적음.<br/><br/>
-	**HA(고가용성, High Availability)** 기능: 네임노드가 고장 나면 HDFS 전체가 망가짐. 가용성을 높이기 위해 HA구성(이중화)를 할 수 있음. 두 대의 서버인 액티브(active) 네임노드와 스탠바이(standby) 네임노드를 이용하여 지원함. 두 네임노드는 동일한 메타 데이터 유지함. 액티브 네임노드에 장애 발생 시 자동으로 스탠바이 네임노드가 액티브 네임노드로 변경됨.<br/><br/><br/>

###	접근 패턴 제한
-	기본적으로 연속적 스트림 읽기를 전제로 함. 랜덤 읽기 방식은 고려하지 않음.<br/><br/>
-	HDFS에서 데이터 기록은 한 번만 이루어지고, 그 이후는 읽기 처리만 가능. 데이터 변경 불가능.<br/><br/><br/><br/>


## MapReduce 프레임워크의 기본적인 특징
---
- MapReduce는 대규모 데이터 집합을 처리하기 위한 프로그래밍 모델임.
- 하나의 잡을 복수의 태스크로 분배하고, 복수의 태스크 트래커를 사용해 병렬로 실행함.<br/><br/><br/>

### MapReduce 처리 흐름
- 크게 ‘맵(Map) 처리’와 ‘리듀스(Reduce) 처리’ 두 단계로 구성됨.<br/><br/>
- 맵 처리는 주로 입력 파일을 한 줄씩 읽어서 필터링 등의 처리를 하고, 리듀스 처리는 데이터 집약을 맡음.<br/><br/>
- 맵 처리와 리듀스 처리 사이에는 ‘셔플(Shuffle) 처리’가 자동적으로 실행됨. 사용자가 처리를 지정해 줄 필요는 없음.<br/><br/><br/>

    1) **맵 처리**
    -	입력 데이터 집합을 분할해서 각각을 맵 태스크에 할당함. 입력 데이터는 HDFS 상의 파일이며 데이터 분할은 MapReduce 프레임워크가 자동으로 수행함.<br/><br/>
    -	MapReduce 프레임워크는 각 맵 태스크를 태스크 트래커에 할당함. 각 맵 태스크는 입력 데이터로부터 한 건씩 key-value 쌍을 꺼내어 사용자가 정의한 Map 처리를 수행하며 처리 결과도 key-value 형태로 출력함.<br/><br/>

    2) **셔플 처리**
    -	맵 처리가 완료되면 MapReduce 프레임워크가 맵 처리 후 데이터를 정렬해서, 같은 키를 가진 데이터를 같은 장소에 모음. 이때 슬레이브 서버 간 네트워크를 통한 전송 발생. 자동적으로 처리됨.<br/><br/>

    3) **리듀스 처리**
    -	key별로 모아진 데이터에 대해 리듀스 처리 진행. key 개수만큼 처리가 이루어짐. 여러 개의 태스크 트래커를 사용하여 병렬로 리듀스 처리를 함.<br/><br/>
